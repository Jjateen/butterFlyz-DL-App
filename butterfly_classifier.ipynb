{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5481697,"sourceType":"datasetVersion","datasetId":456014}],"dockerImageVersionId":30512,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\n\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom sklearn.metrics import classification_report, f1_score , confusion_matrix\n\n\n\n# Tensorflow Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Dense, Dropout , BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers,models,Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('mixed_float16')\n\n\nprint(tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-14T18:25:54.160689Z","iopub.execute_input":"2023-08-14T18:25:54.161073Z","iopub.status.idle":"2023-08-14T18:26:03.058250Z","shell.execute_reply.started":"2023-08-14T18:25:54.161043Z","shell.execute_reply":"2023-08-14T18:26:03.057241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"dataset = {\n             \"train_data\" : \"/kaggle/input/butterfly-images40-species/train\",\n             \"valid_data\" : \"/kaggle/input/butterfly-images40-species/valid\",\n             \"test_data\" : \"/kaggle/input/butterfly-images40-species/test\"\n          }\n\nall_data = []\nfor path in dataset.values():\n    data = {\"imgpath\": [] , \"labels\": [] }\n    category = os.listdir(path)\n\n    for folder in category:\n        folderpath = os.path.join(path , folder)\n        filelist = os.listdir(folderpath)\n        for file in filelist:\n            fpath = os.path.join(folderpath, file)\n            data[\"imgpath\"].append(fpath)\n            data[\"labels\"].append(folder)\n        \n        \n    all_data.append(data.copy())\n    data.clear()\n\n    \n    \ntrain_df = pd.DataFrame(all_data[0] , index=range(len(all_data[0]['imgpath'])))\nvalid_df = pd.DataFrame(all_data[1] , index=range(len(all_data[1]['imgpath'])))\ntest_df = pd.DataFrame(all_data[2] , index=range(len(all_data[2]['imgpath'])))\n\n\n# #Convert labels to numbers\nlb = LabelEncoder()\ntrain_df['encoded_labels'] = lb.fit_transform(train_df['labels'])\nvalid_df['encoded_labels'] = lb.fit_transform(valid_df['labels'])\ntest_df['encoded_labels'] = lb.fit_transform(test_df['labels'])","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:26:03.060867Z","iopub.execute_input":"2023-08-14T18:26:03.061838Z","iopub.status.idle":"2023-08-14T18:26:06.854429Z","shell.execute_reply.started":"2023-08-14T18:26:03.061777Z","shell.execute_reply":"2023-08-14T18:26:06.853487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Traing Data images count per class","metadata":{}},{"cell_type":"code","source":"train  = train_df[\"labels\"].value_counts()\nlabel = train.tolist()\nindex = train.index.tolist()\n\ncolors = [\n    \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\",\n    \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\",\n    \"#aec7e8\", \"#ffbb78\", \"#98df8a\", \"#ff9896\", \"#c5b0d5\",\n    \"#c49c94\", \"#f7b6d2\", \"#c7c7c7\", \"#dbdb8d\", \"#9edae5\",\n    \"#5254a3\", \"#6b6ecf\", \"#bdbdbd\", \"#8ca252\", \"#bd9e39\",\n    \"#ad494a\", \"#8c6d31\", \"#6b6ecf\", \"#e7ba52\", \"#ce6dbd\",\n    \"#9c9ede\", \"#cedb9c\", \"#de9ed6\", \"#ad494a\", \"#d6616b\",\n    \"#f7f7f7\", \"#7b4173\", \"#a55194\", \"#ce6dbd\"\n]\n\n\n\nplt.figure(figsize=(30,30))\nplt.title(\"Training data images count per class\",fontsize=38)\nplt.xlabel('Number of images', fontsize=35)\nplt.ylabel('Classes', fontsize=35)\nplt.barh(index,label, color=colors)\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:26:06.855845Z","iopub.execute_input":"2023-08-14T18:26:06.856197Z","iopub.status.idle":"2023-08-14T18:26:09.083786Z","shell.execute_reply.started":"2023-08-14T18:26:06.856163Z","shell.execute_reply":"2023-08-14T18:26:09.082868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sample(n=15, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:26:09.086472Z","iopub.execute_input":"2023-08-14T18:26:09.086805Z","iopub.status.idle":"2023-08-14T18:26:09.124621Z","shell.execute_reply.started":"2023-08-14T18:26:09.086777Z","shell.execute_reply":"2023-08-14T18:26:09.123737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"----------Train-------------\")\nprint(train_df[[\"imgpath\", \"labels\"]].head(5))\nprint(train_df.shape)\nprint(\"--------Validation----------\")\nprint(valid_df[[\"imgpath\", \"labels\"]].head(5))\nprint(valid_df.shape)\nprint(\"----------Test--------------\")\nprint(test_df[[\"imgpath\", \"labels\"]].head(5))\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:26:09.126231Z","iopub.execute_input":"2023-08-14T18:26:09.126884Z","iopub.status.idle":"2023-08-14T18:26:09.152439Z","shell.execute_reply.started":"2023-08-14T18:26:09.126852Z","shell.execute_reply":"2023-08-14T18:26:09.151525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show sample from data","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,12))\nfor i, row in valid_df.sample(n=16).reset_index().iterrows():\n    plt.subplot(4,4,i+1)\n    image_path = row['imgpath']\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.title(row[\"labels\"])\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:26:09.157165Z","iopub.execute_input":"2023-08-14T18:26:09.159578Z","iopub.status.idle":"2023-08-14T18:26:10.859428Z","shell.execute_reply.started":"2023-08-14T18:26:09.159543Z","shell.execute_reply":"2023-08-14T18:26:10.858570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nBATCH_SIZE = 25\nIMAGE_SIZE = (224, 224)\n\n\ngenerator = ImageDataGenerator(\n    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n    # there could be image augmentation here\n)\n\n# Split the data into three categories.\ntrain_images = generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='imgpath',\n    y_col='labels',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n)\n\nval_images = generator.flow_from_dataframe(\n    dataframe=valid_df,\n    x_col='imgpath',\n    y_col='labels',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\ntest_images = generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='imgpath',\n    y_col='labels',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:26:10.860673Z","iopub.execute_input":"2023-08-14T18:26:10.862056Z","iopub.status.idle":"2023-08-14T18:26:16.219058Z","shell.execute_reply.started":"2023-08-14T18:26:10.862021Z","shell.execute_reply":"2023-08-14T18:26:16.217589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the pretained model\npretrained_model = tf.keras.applications.EfficientNetB0(\n    input_shape=(224, 224, 3),\n    include_top=False, # we don`t need a pre-trained top layer (output layer)\n    weights='imagenet',\n    pooling='max'\n)\n\n# Freezing the layers of a pretrained neural network\nfor i, layer in enumerate(pretrained_model.layers):\n    pretrained_model.layers[i].trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:26:16.220662Z","iopub.execute_input":"2023-08-14T18:26:16.221022Z","iopub.status.idle":"2023-08-14T18:26:22.899568Z","shell.execute_reply.started":"2023-08-14T18:26:16.220990Z","shell.execute_reply":"2023-08-14T18:26:22.898494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training : Transfer Learning","metadata":{}},{"cell_type":"code","source":"num_classes = len(set(train_images.classes))\n\n\n# Data Augmentation Step\naugment = tf.keras.Sequential([\n  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n  layers.experimental.preprocessing.RandomRotation(0.13),\n  layers.experimental.preprocessing.RandomZoom(0.12),\n  layers.experimental.preprocessing.RandomContrast(0.10),\n], name='AugmentationLayer')\n\n\n\ninputs = layers.Input(shape = (224,224,3), name='inputLayer')\nx = augment(inputs)\npretrain_out = pretrained_model(x, training = False)\nx = layers.Dense(256)(pretrain_out)\nx = layers.Activation(activation=\"relu\")(x) \nx = BatchNormalization()(x)\nx = layers.Dropout(0.45)(x)\nx = layers.Dense(num_classes)(x)\noutputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x) # mixed_precision need separated Dense and Activation layers\nmodel = Model(inputs=inputs, outputs=outputs)\n\n\n\nmodel.compile(\n    optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n# model.load_weights('./checkpoints/my_checkpoint')","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:26:22.901057Z","iopub.execute_input":"2023-08-14T18:26:22.901421Z","iopub.status.idle":"2023-08-14T18:26:24.204117Z","shell.execute_reply.started":"2023-08-14T18:26:22.901387Z","shell.execute_reply":"2023-08-14T18:26:24.202997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model.trainable = True\nfor layer in pretrained_model.layers:\n    if isinstance(layer, layers.BatchNormalization): # set BatchNorm layers as not trainable\n        layer.trainable = False\n        \n# let`s see first 10 layers\nfor l in pretrained_model.layers[:10]:\n    print(l.name, l.trainable)\n\nmodel.compile(\n    optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n# model.load_weights('./checkpoints/my_checkpoint')\nprint(model.summary())\nhistory = model.fit(\n    train_images,\n    steps_per_epoch=len(train_images),\n    validation_data=val_images,\n    validation_steps=len(val_images),\n    epochs=45,\n    callbacks=[\n        EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n                               patience = 3,\n                               restore_best_weights = True), # if val loss decreases for 5 epochs in a row, stop training,\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min') \n    ]\n)\nmodel.save_weights('./checkpoints/my_checkpoint')","metadata":{"execution":{"iopub.status.busy":"2023-08-14T18:26:24.208193Z","iopub.execute_input":"2023-08-14T18:26:24.208497Z","iopub.status.idle":"2023-08-14T19:23:40.462366Z","shell.execute_reply.started":"2023-08-14T18:26:24.208472Z","shell.execute_reply":"2023-08-14T19:23:40.461327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the TensorFlow Lite model\nwith open('butter.tflite', 'wb') as f:\n    f.write(tflite_model)\n\nprint(\"TensorFlow Lite model saved as 'butter.tflite'\")","metadata":{"execution":{"iopub.status.busy":"2023-08-14T19:23:40.467591Z","iopub.execute_input":"2023-08-14T19:23:40.469949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display model performance","metadata":{}},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training : Fine Tuning","metadata":{}},{"cell_type":"code","source":"# pretrained_model.trainable = True\n# for layer in pretrained_model.layers:\n#     if isinstance(layer, layers.BatchNormalization): # set BatchNorm layers as not trainable\n#         layer.trainable = False\n        \n# # let`s see first 10 layers\n# for l in pretrained_model.layers[:10]:\n#     print(l.name, l.trainable)\n\n# model.compile(\n#     optimizer=Adam(0.00001), # fine tuning requires very little learning rate\n#     loss='categorical_crossentropy',\n#     metrics=['accuracy']\n# )\n# # model.load_weights('./checkpoints/my_checkpoint')\n# print(model.summary())\n# history = model.fit(\n#     train_images,\n#     steps_per_epoch=len(train_images),\n#     validation_data=val_images,\n#     validation_steps=len(val_images),\n#     epochs=45,\n#     callbacks=[\n#         EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n#                                patience = 3,\n#                                restore_best_weights = True), # if val loss decreases for 5 epochs in a row, stop training,\n#         ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min') \n#     ]\n# )\n# model.save_weights('./checkpoints/my_checkpoint')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display model performance","metadata":{}},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model.evaluate","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# F1 Score / Recall / Precision","metadata":{}},{"cell_type":"code","source":"y_true = test_images.classes\ny_pred = np.argmax(model.predict(test_images), axis = 1)\nf1 = f1_score(y_true, y_pred, average='macro')\nprint(\"F1 Score:\", f1)\nprint(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Predictions","metadata":{}},{"cell_type":"code","source":"classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))\nPredictions = pd.DataFrame({\"Image Index\" : list(range(len(test_images.labels))), \n                            \"Test Labels\" : test_images.labels, \n                            \"Test Classes\" : [classes[i] for i in test_images.labels],\n                            \"Prediction Labels\" : y_pred,\n                            \"Prediction Classes\" : [classes[i] for i in y_pred],\n                            \"Path\": test_images.filenames,\n                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]\n                           })\nPredictions.head(8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Print the most confident errors","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,20))\nfor i, row in Predictions[Predictions[\"Test Labels\"] != Predictions[\"Prediction Labels\"]].sort_values(\"Prediction Probability\").tail(20).reset_index().iterrows():\n    plt.subplot(5,4,i+1)\n    image_path = row['Path']\n    image = Image.open(image_path)\n    plt.imshow(image)\n    plt.title(f'TRUE: {row[\"Test Classes\"]} | PRED: {row[\"Prediction Classes\"]}', fontsize=8)\n    plt.axis('off')\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict_generator(test_images)\ny_pred = np.argmax(preds, axis=1)\ng_dict = test_images.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_images.classes, y_pred)\n\nplt.figure(figsize= (30, 30))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save(\"model_butter.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nimport tensorflow as tf\n\nmoodel = load_model(\"model_butter.h5\")\n\n\nconverter = tf.lite.TFLiteConverter.from_keras_model(moodel)\ntflite_model = converter.convert()\n\nprint(\"model converted\")\n\n# Save the model.\nwith open('butter.tflite', 'wb') as f:\n    f.write(tflite_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}